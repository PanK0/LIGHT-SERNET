{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Light-SERNet inference tests.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i_LBBK1lmar"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the full repository from GitHub\n",
        "\n",
        "Clon the project from my github repository @ https://github.com/PanK0/LIGHT-SERNET.git"
      ],
      "metadata": {
        "id": "C3XEqPcvgzA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PanK0/LIGHT-SERNET.git"
      ],
      "metadata": {
        "id": "e-DbEfyPpfvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move into the main directory\n",
        "\n",
        "Move into the main directory of the repository to be in the proper location to launch the python script for inference tests"
      ],
      "metadata": {
        "id": "REzx3Brrg6t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/LIGHT-SERNET\")"
      ],
      "metadata": {
        "id": "b6SP4Lyjnz9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List the files provided for inference tests\n",
        "\n",
        "Running the lines below they will be listed all the file proposed for inference tests.\n",
        "Except for the four files named\n",
        "\n",
        "\n",
        "*   `EMO-DB_3.0s_Segmented_cross_entropy_float32.tflite`\n",
        "*   `EMO-DB_3.0s_Segmented_cross_entropy_Report.txt`\n",
        "*   `EMO-DB_3.0s_Segmented_cross_entropy_TotalConfusionMatrixNormalized.pdf`\n",
        "*   `EMO-DB_3.0s_Segmented_cross_entropy_TotalConfusionMatrix.pdf`\n",
        "\n",
        "the other files contain in the name some information like\n",
        "\n",
        "\n",
        "*   The **label** of the audio file\n",
        "*   Whether the file **belongs to the EMO-DB Dataset** (simply named with `dataset`)\n",
        "*   Whether the file is a **phrase from the dataset** but it has been recorded by me from a german speaker (simply named with `rec`)\n",
        "*   Whether the file is **NOT a phrase from the dataset** and it has been recorded by me from a german speaker (simply named with `external`)\n",
        "\n",
        "**! ! ! PLEASE CAREFUL :** audio tagged with `rec` and `external` are recorded by me with non-professional instruments with two german speakers that are **NOT ACTRESSES**, so the classification of the content may encounter some impediments.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X1BhWmvnjzL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/LIGHT-SERNET/inference_tests\")\n",
        "!echo \"Operating in directory: LIGHT-SERNET/inference_tests\"\n",
        "!echo \" \"\n",
        "!ls\n",
        "os.chdir(\"/content/LIGHT-SERNET\")"
      ],
      "metadata": {
        "id": "tgAW4vNcjfNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the tests on a file among the files listed above\n",
        "\n",
        "To make inference on a file just run the following line by changing the name of the file you want to classify.\n",
        "\n",
        "The files listed above are the files present in the `inference_tests/` folder of the project.\n",
        "\n",
        "The used model is also present in that folder with the name `EMO-DB_3.0s_Segmented_cross_entropy_float32.tflite`. \n",
        "\n",
        "To change the model train again the Neural Network and then modify the model path in the variable `model_path` in the code in `inference_single_file.py`.\n",
        "\n",
        "If you want to test some other files in the directory just change the file name given in input as argument of `-fn {filename`.\n",
        "\n",
        "\n",
        "\n",
        "**! ! ! PLEASE CAREFUL:** if you train a new model, the classes can be mixed, and so you'll have to reassign the correct correspondend classes in the dictionary in the code."
      ],
      "metadata": {
        "id": "CF_l55kjmI84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference_single_file.py -id 3 -at \"all\" -ln \"cross_entropy\" -it \"mfcc\" -fn \"happiness_external.wav\""
      ],
      "metadata": {
        "id": "xW2EhYWK0oQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Go back in the directory tree and delete the repository\n",
        "\n",
        "Do this only if you want to start this notebook from the principle without disconnecting it."
      ],
      "metadata": {
        "id": "Dh5zQamahja7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content\")\n",
        "!ls\n",
        "!rm -r LIGHT-SERNET"
      ],
      "metadata": {
        "id": "TSmdNok-B-5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}